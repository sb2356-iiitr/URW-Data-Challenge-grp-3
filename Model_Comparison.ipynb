{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: catboost in c:\\users\\soumy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in c:\\users\\soumy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\soumy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from catboost) (3.9.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in c:\\users\\soumy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from catboost) (2.1.3)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\soumy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from catboost) (2.2.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\soumy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from catboost) (1.14.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\soumy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in c:\\users\\soumy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\soumy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\soumy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\soumy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\soumy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\soumy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\soumy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->catboost) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\soumy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->catboost) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\soumy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->catboost) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\soumy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->catboost) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\soumy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->catboost) (3.2.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\soumy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from plotly->catboost) (9.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\soumy\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\soumy\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\soumy\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from catboost import CatBoostRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3854, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mall_id</th>\n",
       "      <th>block_id</th>\n",
       "      <th>block_type</th>\n",
       "      <th>store_code</th>\n",
       "      <th>store_name</th>\n",
       "      <th>retailer_code</th>\n",
       "      <th>bl1_label</th>\n",
       "      <th>bl2_label</th>\n",
       "      <th>bl3_label</th>\n",
       "      <th>gla</th>\n",
       "      <th>gla_category</th>\n",
       "      <th>cur_code</th>\n",
       "      <th>sales_r12m</th>\n",
       "      <th>total_costs_r12m</th>\n",
       "      <th>sales_per_cost</th>\n",
       "      <th>has_financials</th>\n",
       "      <th>sri_score</th>\n",
       "      <th>has_sri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>6990</td>\n",
       "      <td>CELL</td>\n",
       "      <td>1024429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>478</td>\n",
       "      <td>Food Stores &amp; Mass Merchandise</td>\n",
       "      <td>Hypermarkets</td>\n",
       "      <td>Hypermarkets</td>\n",
       "      <td>5125.06</td>\n",
       "      <td>LARGE UNITS</td>\n",
       "      <td>PLN</td>\n",
       "      <td>3925410.561</td>\n",
       "      <td>275000.72780</td>\n",
       "      <td>14.274182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>1669</td>\n",
       "      <td>CELL</td>\n",
       "      <td>1313684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137432</td>\n",
       "      <td>Services</td>\n",
       "      <td>Other product-related services</td>\n",
       "      <td>Others Products related services</td>\n",
       "      <td>116.00</td>\n",
       "      <td>SMALL UNITS</td>\n",
       "      <td>EUR</td>\n",
       "      <td>33232.848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>6436</td>\n",
       "      <td>CELL</td>\n",
       "      <td>1001163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>478</td>\n",
       "      <td>Food Stores &amp; Mass Merchandise</td>\n",
       "      <td>Hypermarkets</td>\n",
       "      <td>Hypermarkets</td>\n",
       "      <td>15374.00</td>\n",
       "      <td>LARGE UNITS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>4653</td>\n",
       "      <td>CELL</td>\n",
       "      <td>1312660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108125</td>\n",
       "      <td>Culture &amp; Media &amp; Technology</td>\n",
       "      <td>Books, Music &amp; Multimedia</td>\n",
       "      <td>Bookstore &amp; stationery</td>\n",
       "      <td>85.00</td>\n",
       "      <td>SMALL UNITS</td>\n",
       "      <td>CZK</td>\n",
       "      <td>87862.674</td>\n",
       "      <td>20984.35704</td>\n",
       "      <td>4.187056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>1642</td>\n",
       "      <td>KIOSK</td>\n",
       "      <td>1314473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55270</td>\n",
       "      <td>Food Stores &amp; Mass Merchandise</td>\n",
       "      <td>Frozen food</td>\n",
       "      <td>Frozen food</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mall_id  block_id block_type  store_code store_name  retailer_code  \\\n",
       "0       33      6990       CELL     1024429        NaN            478   \n",
       "1       16      1669       CELL     1313684        NaN         137432   \n",
       "2       26      6436       CELL     1001163        NaN            478   \n",
       "3       10      4653       CELL     1312660        NaN         108125   \n",
       "4       16      1642      KIOSK     1314473        NaN          55270   \n",
       "\n",
       "                        bl1_label                       bl2_label  \\\n",
       "0  Food Stores & Mass Merchandise                    Hypermarkets   \n",
       "1                        Services  Other product-related services   \n",
       "2  Food Stores & Mass Merchandise                    Hypermarkets   \n",
       "3    Culture & Media & Technology       Books, Music & Multimedia   \n",
       "4  Food Stores & Mass Merchandise                     Frozen food   \n",
       "\n",
       "                          bl3_label       gla gla_category cur_code  \\\n",
       "0                      Hypermarkets   5125.06  LARGE UNITS      PLN   \n",
       "1  Others Products related services    116.00  SMALL UNITS      EUR   \n",
       "2                      Hypermarkets  15374.00  LARGE UNITS      NaN   \n",
       "3            Bookstore & stationery     85.00  SMALL UNITS      CZK   \n",
       "4                       Frozen food       NaN          NaN      NaN   \n",
       "\n",
       "    sales_r12m  total_costs_r12m  sales_per_cost  has_financials  sri_score  \\\n",
       "0  3925410.561      275000.72780       14.274182             1.0        NaN   \n",
       "1    33232.848               NaN             NaN             1.0        NaN   \n",
       "2          NaN               NaN             NaN             NaN        NaN   \n",
       "3    87862.674       20984.35704        4.187056             1.0        NaN   \n",
       "4          NaN               NaN             NaN             NaN        NaN   \n",
       "\n",
       "   has_sri  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  \n",
       "3      NaN  \n",
       "4      NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"feature_engineered_master.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines the target (`sales_r12m`), drops rows missing it, and creates `log_sales = log1p(sales)` (log scale stabilizes skew); `y` is what models learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after cleaning: 3609\n"
     ]
    }
   ],
   "source": [
    "TARGET = \"sales_r12m\"\n",
    "\n",
    "# Drop rows with missing target\n",
    "df = df.dropna(subset=[TARGET])\n",
    "\n",
    "# Log-transform target (recommended)\n",
    "df[\"log_sales\"] = np.log1p(df[TARGET])\n",
    "y = df[\"log_sales\"]\n",
    "\n",
    "print(\"Rows after cleaning:\", df.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Builds the feature matrix `X` by dropping identifiers/leak-prone columns, and sets `groups = mall_id` so validation splits don’t mix the same mall across train/val.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP_COLS = [\n",
    "    TARGET,\n",
    "    \"log_sales\",\n",
    "    \"store_code\",\n",
    "    \"block_id\",\n",
    "    \"store_name\"\n",
    "]\n",
    "\n",
    "X = df.drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "groups = df[\"mall_id\"]  # group-aware split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits features into categorical vs numeric columns (based on dtype) so we can preprocess them differently; prints lists to sanity-check feature typing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features: ['block_type', 'bl1_label', 'bl2_label', 'bl3_label', 'gla_category', 'cur_code']\n",
      "Numeric features: ['mall_id', 'retailer_code', 'gla', 'total_costs_r12m', 'sales_per_cost', 'has_financials', 'sri_score', 'has_sri']\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(exclude=[\"object\"]).columns.tolist()\n",
    "\n",
    "print(\"Categorical features:\", categorical_cols)\n",
    "print(\"Numeric features:\", numeric_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a 5-fold GroupKFold split and takes the first fold: train/val are separated by `mall_id` (interpretation: val simulates “new malls”).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "train_idx, val_idx = next(gkf.split(X, y, groups))\n",
    "\n",
    "X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trains an Elastic Net baseline with full preprocessing (median impute + scale numeric, most-frequent impute + one-hot categorical) and outputs (RMSE, R²) on log-sales: lower RMSE and higher R² are better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.9599346088201473), 0.43742864901528744)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify columns again (safe)\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(exclude=[\"object\"]).columns.tolist()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "elastic_net = Pipeline(steps=[\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42))\n",
    "])\n",
    "\n",
    "elastic_net.fit(X_train, y_train)\n",
    "pred_en = elastic_net.predict(X_val)\n",
    "\n",
    "rmse_en = np.sqrt(mean_squared_error(y_val, pred_en))\n",
    "r2_en = r2_score(y_val, pred_en)\n",
    "\n",
    "rmse_en, r2_en\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trains a Random Forest on *numeric-only* features (median-imputed), then evaluates on validation; RMSE/R² interpret the same way as above (but note: this ignores categorical variables entirely).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.6008661580551038), 0.7795806074132077)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "X_train_num = num_imputer.fit_transform(X_train[numeric_cols])\n",
    "X_val_num = num_imputer.transform(X_val[numeric_cols])\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=12,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train_num, y_train)\n",
    "pred_rf = rf.predict(X_val_num)\n",
    "\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_val, pred_rf))\n",
    "r2_rf = r2_score(y_val, pred_rf)\n",
    "rmse_rf, r2_rf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleans categorical columns for CatBoost by converting them to strings and replacing missing values with \"missing\" (interpretation: ensures CatBoost won’t crash on NaNs in categoricals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in categorical (train): 0\n",
      "NaNs in categorical (val): 0\n"
     ]
    }
   ],
   "source": [
    "# Make sure we're not working on views\n",
    "X_train = X_train.copy()\n",
    "X_val = X_val.copy()\n",
    "\n",
    "# Recompute categorical cols robustly: treat low-cardinality ints as categoricals if needed\n",
    "categorical_cols = X_train.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "# Force ALL categorical cols to string and fill NaNs\n",
    "for col in categorical_cols:\n",
    "    X_train[col] = X_train[col].astype(str).fillna(\"missing\")\n",
    "    X_val[col] = X_val[col].astype(str).fillna(\"missing\")\n",
    "\n",
    "# EXTRA SAFETY: replace any remaining NaN anywhere in categorical cols (covers weird cases)\n",
    "X_train[categorical_cols] = X_train[categorical_cols].replace({np.nan: \"missing\"})\n",
    "X_val[categorical_cols] = X_val[categorical_cols].replace({np.nan: \"missing\"})\n",
    "\n",
    "# Sanity check: if this prints >0, something is still wrong\n",
    "print(\"NaNs in categorical (train):\", X_train[categorical_cols].isna().sum().sum())\n",
    "print(\"NaNs in categorical (val):\", X_val[categorical_cols].isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fits CatBoost on the mixed feature set (numeric + categorical indices) and reports RMSE/R² on log-sales; if CatBoost RMSE is lowest, it’s your best model so far.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.560312053557527), 0.8083299558511131)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features_idx = [X_train.columns.get_loc(col) for col in categorical_cols]\n",
    "\n",
    "cat = CatBoostRegressor(\n",
    "    iterations=800,\n",
    "    depth=8,\n",
    "    learning_rate=0.05,\n",
    "    loss_function=\"RMSE\",\n",
    "    random_seed=42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "cat.fit(X_train, y_train, cat_features=cat_features_idx)\n",
    "\n",
    "pred_cat = cat.predict(X_val)\n",
    "\n",
    "rmse_cat = np.sqrt(mean_squared_error(y_val, pred_cat))\n",
    "r2_cat = r2_score(y_val, pred_cat)\n",
    "\n",
    "rmse_cat, r2_cat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM (Gradient Boosting Trees)\n",
    "\n",
    "Trains a LightGBM regressor on the same train/validation split. We let LightGBM handle categorical features by converting them to pandas `category` dtype.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1458\n",
      "[LightGBM] [Info] Number of data points in the train set: 2881, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 11.873930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.530858104625662), 0.8279513707968207)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Copy to avoid side effects\n",
    "X_train_lgb = X_train.copy()\n",
    "X_val_lgb = X_val.copy()\n",
    "\n",
    "# Make categorical cols category dtype for LightGBM\n",
    "for col in categorical_cols:\n",
    "    X_train_lgb[col] = X_train_lgb[col].astype('category')\n",
    "    X_val_lgb[col] = X_val_lgb[col].astype('category')\n",
    "\n",
    "lgbm = lgb.LGBMRegressor(\n",
    "    n_estimators=5000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=63,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lgbm.fit(\n",
    "    X_train_lgb, y_train,\n",
    "    eval_set=[(X_val_lgb, y_val)],\n",
    "    eval_metric='rmse',\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=200, verbose=False)]\n",
    ")\n",
    "\n",
    "pred_lgb = lgbm.predict(X_val_lgb, num_iteration=lgbm.best_iteration_)\n",
    "rmse_lgb = np.sqrt(mean_squared_error(y_val, pred_lgb))\n",
    "r2_lgb = r2_score(y_val, pred_lgb)\n",
    "\n",
    "rmse_lgb, r2_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HistGradientBoostingRegressor (Sklearn)\n",
    "\n",
    "A strong, fast baseline that works well on tabular data. Uses one-hot encoding for categoricals via a preprocessing pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "# # Reuse the same preprocessor pattern (impute + one-hot)\n",
    "# hgb = Pipeline(steps=[\n",
    "#     ('prep', preprocessor),\n",
    "#     ('model', HistGradientBoostingRegressor(\n",
    "#         learning_rate=0.05,\n",
    "#         max_depth=8,\n",
    "#         max_iter=500,\n",
    "#         random_state=42\n",
    "#     ))\n",
    "# ])\n",
    "\n",
    "# hgb.fit(X_train, y_train)\n",
    "# pred_hgb = hgb.predict(X_val)\n",
    "\n",
    "# rmse_hgb = np.sqrt(mean_squared_error(y_val, pred_hgb))\n",
    "# r2_hgb = r2_score(y_val, pred_hgb)\n",
    "\n",
    "# rmse_hgb, r2_hgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a comparison table across Elastic Net / Random Forest / CatBoost and sorts by RMSE (interpretation: top row = best on log-scale RMSE).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.8179268185826872), 0.5915647573125506)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# XGBoost with the same preprocessing (impute + one-hot) as other baselines\n",
    "xgb_model = Pipeline(steps=[\n",
    "    ('prep', preprocessor),\n",
    "    ('model', xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=5,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        reg_alpha=0.0,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        tree_method='hist'\n",
    "    ))\n",
    "])\n",
    "\n",
    "# NOTE: sklearn Pipeline doesn't expose early stopping cleanly without splitting preprocessed arrays.\n",
    "# For consistency with the notebook structure, we run without early stopping here.\n",
    "# (If you want early stopping, I can give a small helper to pre-transform and pass eval_set.)\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "pred_xgb = xgb_model.predict(X_val)\n",
    "\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_val, pred_xgb))\n",
    "r2_xgb = r2_score(y_val, pred_xgb)\n",
    "\n",
    "rmse_xgb, r2_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE (log sales)</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.530858</td>\n",
       "      <td>0.827951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.560312</td>\n",
       "      <td>0.808330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.600866</td>\n",
       "      <td>0.779581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.817927</td>\n",
       "      <td>0.591565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elastic Net</td>\n",
       "      <td>0.959935</td>\n",
       "      <td>0.437429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  RMSE (log sales)        R2\n",
       "3       LightGBM          0.530858  0.827951\n",
       "2       CatBoost          0.560312  0.808330\n",
       "1  Random Forest          0.600866  0.779581\n",
       "4        XGBoost          0.817927  0.591565\n",
       "0    Elastic Net          0.959935  0.437429"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Elastic Net', 'Random Forest', 'CatBoost', 'LightGBM', 'XGBoost'],\n",
    "    'RMSE (log sales)': [rmse_en, rmse_rf, rmse_cat, rmse_lgb, rmse_xgb],\n",
    "    'R2': [r2_en, r2_rf, r2_cat, r2_lgb, r2_xgb]\n",
    "})\n",
    "\n",
    "results.sort_values('RMSE (log sales)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts CatBoost predictions back to euros using `expm1` and computes RMSE in original sales units (interpretation: this is the “business-readable” error magnitude).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(541434.6385416274)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cat_eur = np.expm1(pred_cat)\n",
    "y_val_eur = np.expm1(y_val)\n",
    "\n",
    "rmse_eur = np.sqrt(mean_squared_error(y_val_eur, pred_cat_eur))\n",
    "rmse_eur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows summary stats of actual validation sales in euros (interpretation: helps judge whether the euro-RMSE is large or small relative to typical sales levels).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7.280000e+02\n",
       "mean     3.304868e+05\n",
       "std      8.961972e+05\n",
       "min      1.139544e+03\n",
       "25%      6.094097e+04\n",
       "50%      1.092759e+05\n",
       "75%      2.745195e+05\n",
       "max      1.509674e+07\n",
       "Name: log_sales, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_eur.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes MAE in euros (interpretation: average absolute error; often easier to explain than RMSE and less sensitive to huge outliers).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(100750.36491764447)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_val_eur, pred_cat_eur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes mean absolute error by `gla_category` (interpretation: tells you which store-size segment the model struggles with most—higher = worse).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gla_category\n",
       "LARGE UNITS    1.066235e+06\n",
       "MSU            2.770588e+05\n",
       "SMALL UNITS    3.337651e+04\n",
       "nan            1.785308e+04\n",
       "Name: abs_error, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume you have gla or gla_category\n",
    "df_val = X_val.copy()\n",
    "df_val[\"actual\"] = y_val_eur\n",
    "df_val[\"pred\"] = pred_cat_eur\n",
    "\n",
    "df_val[\"abs_error\"] = np.abs(df_val[\"actual\"] - df_val[\"pred\"])\n",
    "\n",
    "df_val.groupby(\"gla_category\")[\"abs_error\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregates predictions vs actuals at the mall level (sum of store sales per mall) and summarizes absolute error distribution (interpretation: shows where the model is most wrong by mall).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4.000000e+00\n",
       "mean     1.105177e+07\n",
       "std      1.210606e+07\n",
       "min      9.578605e+05\n",
       "25%      4.848634e+06\n",
       "50%      7.333593e+06\n",
       "75%      1.353673e+07\n",
       "max      2.858204e+07\n",
       "Name: abs_error, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val[\"mall_id\"] = groups.iloc[val_idx].values\n",
    "\n",
    "mall_error = (\n",
    "    df_val\n",
    "    .groupby(\"mall_id\")[[\"actual\", \"pred\"]]\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "mall_error[\"abs_error\"] = np.abs(\n",
    "    mall_error[\"actual\"] - mall_error[\"pred\"]\n",
    ")\n",
    "\n",
    "mall_error[\"abs_error\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
